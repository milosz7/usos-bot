{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T11:08:56.338724Z",
     "start_time": "2024-10-29T11:08:55.615585Z"
    }
   },
   "source": [
    "from USOSDataLoader import USOSDataLoader\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from uuid import uuid4\n",
    "import logging\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:10:24.168896Z",
     "start_time": "2024-10-29T11:08:57.852261Z"
    }
   },
   "cell_type": "code",
   "source": "documents = USOSDataLoader().get_documents()",
   "id": "846bc6e7cd123d0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pdf links...: 100%|██████████| 34/34 [00:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading web data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pdf data...: 100%|██████████| 47/47 [00:32<00:00,  1.45it/s]\n",
      "Preprocessing documents...: 100%|██████████| 81/81 [00:00<00:00, 3964.00it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:48:33.721319Z",
     "start_time": "2024-10-29T11:48:28.332807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename=\"failed_chunks.log\", level=logging.ERROR)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v3\",\n",
    "                                   model_kwargs={\"trust_remote_code\": True},\n",
    "                                   encode_kwargs={\"task\": \"retrieval.query\"})\n",
    "\n",
    "pc = Pinecone(os.environ.get(\"PINECONE_API_KEY\"))"
   ],
   "id": "32fc07d1e47bf2c8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:48:48.277601Z",
     "start_time": "2024-10-29T11:48:41.135475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index_name = \"usos-bot-questions\"\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)"
   ],
   "id": "e64eeba7283378ed",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:49:11.808414Z",
     "start_time": "2024-10-29T11:49:11.803269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuestionList(BaseModel):\n",
    "    question_list: list[str] = Field(..., title=\"List of questions generated for the document or fragment\")\n",
    "\n",
    "\n",
    "def clean_and_filter_questions(questions: list[str]) -> list[str]:\n",
    "    cleaned_questions = []\n",
    "    for question in questions:\n",
    "        cleaned_question = re.sub(r'^\\d+\\.\\s*', '', question.strip())\n",
    "        if cleaned_question.endswith('?'):\n",
    "            cleaned_questions.append(cleaned_question)\n",
    "    return cleaned_questions\n",
    "\n",
    "\n",
    "def llm_chain(llm, text, n_questions, prompt):\n",
    "    chain = prompt | llm.with_structured_output(QuestionList)\n",
    "    input_data = {\"context\": text, \"num_questions\": n_questions}\n",
    "    try:\n",
    "        result = chain.invoke(input_data)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        match = re.search(r\"\\d+m\\d+\\.\\d+s|\\d+.\\ds|\\d+m\", e.message)\n",
    "        if match:\n",
    "            print(e.message)\n",
    "            raise Exception(e)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def generate_questions(text: str, n_questions, api_key=None) -> list[str]:\n",
    "    if api_key:\n",
    "        llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0, api_key=api_key)\n",
    "    else:    \n",
    "        llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0)\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"num_questions\"],\n",
    "        template=\"Using the context data: {context}\\n\\nGenerate a list of at least {num_questions} \"\n",
    "                 \"possible questions that can be asked about this context. Ensure the questions are \"\n",
    "                 \"directly answerable within the context and do not include any answers or headers. \"\n",
    "                 \"The questions should be in the same language as the context. \"\n",
    "                 \"Separate the questions with a new line character.\"\n",
    "    )\n",
    "\n",
    "    prompt_secondary = PromptTemplate(\n",
    "        input_variables=[\"context\", \"num_questions\"],\n",
    "        template=\"Using the context data: {context}\\n\\nGenerate a list of at least {num_questions} \"\n",
    "                 \"possible questions that can be asked about this context. Ensure the questions are \"\n",
    "                 \"directly answerable within the context and do not include any answers or headers. \"\n",
    "                 \"The questions should be in the Polish language. \"\n",
    "                 \"Separate the questions with a new line character.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    result = llm_chain(llm, text, n_questions, prompt) or llm_chain(llm, text, n_questions, prompt_secondary)\n",
    "    if result is None:\n",
    "        logger.error(f\"FAILED CHUNK: {text}\")\n",
    "        return []\n",
    "        \n",
    "    questions = result.question_list\n",
    "\n",
    "    filtered_questions = clean_and_filter_questions(questions)\n",
    "    return list(set(filtered_questions))\n",
    "\n",
    "\n",
    "def split_document(document: str, chunk_size: int, chunk_overlap: int) -> list[str]:\n",
    "    tokens = re.findall(r'\\b\\w+\\b', document)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - chunk_overlap):\n",
    "        chunk_tokens = tokens[i:i + chunk_size]\n",
    "        chunks.append(chunk_tokens)\n",
    "        if i + chunk_size >= len(tokens):\n",
    "            break\n",
    "    return [\" \".join(chunk) for chunk in chunks]\n",
    "\n",
    "\n",
    "def print_document(comment: str, document: Document) -> None:\n",
    "    print(\n",
    "        f'{comment} (type: {document.metadata[\"type\"]}, index: {document.metadata[\"index\"]}): {document.page_content}')"
   ],
   "id": "dc82e492b790d2e9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:49:14.908647Z",
     "start_time": "2024-10-29T11:49:14.906530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_sleep_time(raw_sleep):\n",
    "    SECONDS_IN_MINUTE = 60\n",
    "    mins_match = re.search(\"\\\\d+(?=m)\", raw_sleep)\n",
    "    if mins_match:\n",
    "        mins_match = int(mins_match.group(0))\n",
    "        \n",
    "    seconds_match = re.search(r\"\\d+\\.\\d+(?=s)\", raw_sleep)\n",
    "    if seconds_match:\n",
    "        seconds_match = math.ceil(float(seconds_match.group(0)))\n",
    "        \n",
    "    return SECONDS_IN_MINUTE * mins_match + seconds_match"
   ],
   "id": "c83e8592c8dcc529",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Routine for processing fragments with switching keys",
   "id": "f96609e016e4e4c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:49:16.714897Z",
     "start_time": "2024-10-29T11:49:16.711182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import cycle\n",
    "\n",
    "api_keys = os.environ.get(\"API_KEYS\").split(\"||\")\n",
    "api_keys_iter = cycle(api_keys)\n",
    "\n",
    "def add_fragment(fragment, i, j, counter, source, api_key):\n",
    "    knowledge_base = [Document(\n",
    "        page_content=fragment,\n",
    "        metadata=dict(type=\"ORIGINAL\", index=counter, source=source, orig_text=fragment)\n",
    "    )]\n",
    "    questions = generate_questions(fragment, n_questions=20, api_key=api_key)\n",
    "    knowledge_base.extend([\n",
    "        Document(page_content=question,\n",
    "                 metadata=dict(type=\"AUGMENTED\", index=counter + idx, orig_text=fragment))\n",
    "        for idx, question in enumerate(questions)\n",
    "    ])\n",
    "    counter += len(questions)\n",
    "    print(f'Text document {i} Text fragment {j} - generated: {len(questions)} questions')\n",
    "\n",
    "    uuids = [str(uuid4()) for _ in range(len(knowledge_base))]\n",
    "    vectorstore.add_documents(documents=knowledge_base, ids=uuids)\n",
    "\n",
    "    return counter\n",
    "\n",
    "fifteen_minutes_in_sec = 900\n",
    "\n",
    "def process_fragments(documents: list[Document], chunk_size: int, chunk_overlap: int, counter: int = 0):\n",
    "    current_key = next(api_keys_iter)\n",
    "    for i, document in enumerate(documents):\n",
    "        text = document.page_content\n",
    "        text_fragments = split_document(text, chunk_size, chunk_overlap)\n",
    "        \n",
    "        for j, fragment in enumerate(text_fragments):\n",
    "            print(f\"Document {i} - split into {len(text_fragments)}\")\n",
    "            try:\n",
    "                counter = add_fragment(fragment, i, j, counter, source=document.metadata[\"source\"], api_key=current_key)\n",
    "            except Exception as e:\n",
    "                current_key = next(api_keys_iter)\n",
    "                print(\"Switching Keys\")\n",
    "                logger.error(f\"FAILED TO PARSE: DOCUMENT: {i}, FRAGMENT: {j}, COUNTER: {counter} - also accessible in the database.\")\n",
    "                # if no match - let it crash\n",
    "                counter = add_fragment(fragment, i, j, counter, source=document.metadata[\"source\"], api_key=current_key)"
   ],
   "id": "e080bd0e659146b7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Routine for processing fragments",
   "id": "3d4e3d02800a3c2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T21:29:01.557187Z",
     "start_time": "2024-10-28T21:29:01.553305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_fragment(fragment, i, j, counter, source):\n",
    "    knowledge_base = [Document(\n",
    "        page_content=fragment,\n",
    "        metadata=dict(type=\"ORIGINAL\", index=counter, source=source, orig_text=fragment)\n",
    "    )]\n",
    "    questions = generate_questions(fragment, n_questions=20)\n",
    "    knowledge_base.extend([\n",
    "        Document(page_content=question,\n",
    "                 metadata=dict(type=\"AUGMENTED\", index=counter + idx, orig_text=fragment))\n",
    "        for idx, question in enumerate(questions)\n",
    "    ])\n",
    "    counter += len(questions)\n",
    "    print(f'Text document {i} Text fragment {j} - generated: {len(questions)} questions')\n",
    "\n",
    "    uuids = [str(uuid4()) for _ in range(len(knowledge_base))]\n",
    "    vectorstore.add_documents(documents=knowledge_base, ids=uuids)\n",
    "\n",
    "    return counter\n",
    "\n",
    "fifteen_minutes_in_sec = 900\n",
    "\n",
    "def process_fragments(documents: list[Document], chunk_size: int, chunk_overlap: int, counter: int = 0):\n",
    "    for i, document in enumerate(documents):\n",
    "        text = document.page_content\n",
    "        text_fragments = split_document(text, chunk_size, chunk_overlap)\n",
    "        \n",
    "        for j, fragment in enumerate(text_fragments):\n",
    "            print(f\"Document {i} - split into {len(text_fragments)}\")\n",
    "            try:\n",
    "                counter = add_fragment(fragment, i, j, counter, source=document.metadata[\"source\"])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                match = re.search(r\"\\d+m\\d+\\.\\d+s|\\d+.\\ds|\\d+m\", e.message)\n",
    "                if match:\n",
    "                    match = match.group(0)\n",
    "                    sleep_parsed = parse_sleep_time(match)\n",
    "                    if sleep_parsed > fifteen_minutes_in_sec:\n",
    "                        logger.error(f\"FAILED TO PARSE: DOCUMENT: {i}, FRAGMENT: {j}, COUNTER: {counter} - also accessible in the database. MESSAGE: {e.message}\")\n",
    "                        raise RuntimeError(\"Sleep time too long\")\n",
    "                    print(f\"Sleeping for {sleep_parsed} seconds...\")\n",
    "                    for _ in tqdm(range(sleep_parsed)):\n",
    "                        time.sleep(1)\n",
    "                # if no match - let it crash\n",
    "                counter = add_fragment(fragment, i, j, counter, source=document.metadata[\"source\"])"
   ],
   "id": "1e8e3dbd8f9d2ee3",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Routine for adding document by documents with logging",
   "id": "cb1593e733913553"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_document(document, chunk_size, chunk_overlap, i, counter):\n",
    "    knowledge_base = []\n",
    "    text = document.page_content\n",
    "    text_fragments = split_document(text, chunk_size, chunk_overlap)\n",
    "    print(f\"Document {i} - split into {len(text_fragments)}\")\n",
    "    for j, fragment in enumerate(text_fragments):\n",
    "        knowledge_base.append(\n",
    "            Document(\n",
    "                page_content=fragment,\n",
    "                metadata=dict(type=\"ORIGINAL\", index=counter, source=document.metadata[\"source\"], text=fragment)\n",
    "            )\n",
    "        )\n",
    "        questions = generate_questions(text, n_questions=20)\n",
    "        knowledge_base.extend([\n",
    "            Document(page_content=question,\n",
    "                     metadata={\"type\": \"AUGMENTED\", \"index\": counter + idx, \"text\": fragment})\n",
    "            for idx, question in enumerate(questions)\n",
    "        ])\n",
    "        counter += len(questions)\n",
    "        print(f'Text document {i} Text fragment {j} - generated: {len(questions)} questions')\n",
    "    \n",
    "    uuids = [str(uuid4()) for _ in range(len(knowledge_base))]\n",
    "    vectorstore.add_documents(documents=knowledge_base, ids=uuids)\n",
    "\n",
    "\n",
    "def process_documents(documents: list[Document], chunk_size: int, chunk_overlap: int, counter: int = 0):\n",
    "    for i, document in enumerate(documents):\n",
    "        try:\n",
    "            counter = add_document(document, chunk_size, chunk_overlap, i, counter)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"FAILED TO PARSE: DOCUMENT: {i}, COUNTER: {counter} - also accessible in the database. MESSAGE: {e.message}\")"
   ],
   "id": "60cd2e7d86fc1a0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:10:07.254073Z",
     "start_time": "2024-10-29T11:49:22.370362Z"
    }
   },
   "cell_type": "code",
   "source": "process_fragments(documents, 1000, 200)",
   "id": "96b954dd42302b19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 - split into 2\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jbanafxyf6w921a61ed2qvmx` on : Limit 200000, Used 199424, Requested 1991. Please try again in 10m11.057s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Switching Keys\n",
      "Text document 0 Text fragment 0 - generated: 21 questions\n",
      "Document 0 - split into 2\n",
      "Text document 0 Text fragment 1 - generated: 20 questions\n",
      "Document 1 - split into 2\n",
      "Text document 1 Text fragment 0 - generated: 30 questions\n",
      "Document 1 - split into 2\n",
      "Text document 1 Text fragment 1 - generated: 20 questions\n",
      "Document 2 - split into 1\n",
      "Text document 2 Text fragment 0 - generated: 21 questions\n",
      "Document 3 - split into 1\n",
      "Text document 3 Text fragment 0 - generated: 20 questions\n",
      "Document 4 - split into 1\n",
      "Text document 4 Text fragment 0 - generated: 20 questions\n",
      "Document 5 - split into 1\n",
      "Text document 5 Text fragment 0 - generated: 20 questions\n",
      "Document 6 - split into 1\n",
      "Text document 6 Text fragment 0 - generated: 21 questions\n",
      "Document 7 - split into 1\n",
      "Text document 7 Text fragment 0 - generated: 20 questions\n",
      "Document 8 - split into 1\n",
      "Text document 8 Text fragment 0 - generated: 21 questions\n",
      "Document 9 - split into 1\n",
      "Text document 9 Text fragment 0 - generated: 21 questions\n",
      "Document 10 - split into 1\n",
      "Text document 10 Text fragment 0 - generated: 21 questions\n",
      "Document 12 - split into 1\n",
      "Text document 12 Text fragment 0 - generated: 20 questions\n",
      "Document 13 - split into 1\n",
      "Text document 13 Text fragment 0 - generated: 20 questions\n",
      "Document 14 - split into 1\n",
      "Text document 14 Text fragment 0 - generated: 21 questions\n",
      "Document 15 - split into 1\n",
      "Text document 15 Text fragment 0 - generated: 28 questions\n",
      "Document 16 - split into 1\n",
      "Text document 16 Text fragment 0 - generated: 21 questions\n",
      "Document 17 - split into 1\n",
      "Text document 17 Text fragment 0 - generated: 22 questions\n",
      "Document 18 - split into 1\n",
      "Text document 18 Text fragment 0 - generated: 20 questions\n",
      "Document 19 - split into 1\n",
      "Text document 19 Text fragment 0 - generated: 20 questions\n",
      "Document 21 - split into 2\n",
      "Text document 21 Text fragment 0 - generated: 23 questions\n",
      "Document 21 - split into 2\n",
      "Text document 21 Text fragment 1 - generated: 21 questions\n",
      "Document 22 - split into 1\n",
      "Text document 22 Text fragment 0 - generated: 20 questions\n",
      "Document 23 - split into 1\n",
      "Text document 23 Text fragment 0 - generated: 20 questions\n",
      "Document 24 - split into 1\n",
      "Text document 24 Text fragment 0 - generated: 20 questions\n",
      "Document 25 - split into 1\n",
      "Text document 25 Text fragment 0 - generated: 21 questions\n",
      "Document 26 - split into 1\n",
      "Text document 26 Text fragment 0 - generated: 24 questions\n",
      "Document 27 - split into 1\n",
      "Text document 27 Text fragment 0 - generated: 21 questions\n",
      "Document 29 - split into 1\n",
      "Text document 29 Text fragment 0 - generated: 21 questions\n",
      "Document 30 - split into 1\n",
      "Text document 30 Text fragment 0 - generated: 21 questions\n",
      "Document 31 - split into 1\n",
      "Text document 31 Text fragment 0 - generated: 21 questions\n",
      "Document 32 - split into 1\n",
      "Text document 32 Text fragment 0 - generated: 21 questions\n",
      "Document 33 - split into 1\n",
      "Text document 33 Text fragment 0 - generated: 23 questions\n",
      "Document 34 - split into 1\n",
      "Text document 34 Text fragment 0 - generated: 21 questions\n",
      "Document 35 - split into 1\n",
      "Text document 35 Text fragment 0 - generated: 21 questions\n",
      "Document 36 - split into 4\n",
      "Text document 36 Text fragment 0 - generated: 22 questions\n",
      "Document 36 - split into 4\n",
      "Text document 36 Text fragment 1 - generated: 21 questions\n",
      "Document 36 - split into 4\n",
      "Text document 36 Text fragment 2 - generated: 22 questions\n",
      "Document 36 - split into 4\n",
      "Text document 36 Text fragment 3 - generated: 20 questions\n",
      "Document 37 - split into 1\n",
      "Text document 37 Text fragment 0 - generated: 20 questions\n",
      "Document 38 - split into 3\n",
      "Text document 38 Text fragment 0 - generated: 21 questions\n",
      "Document 38 - split into 3\n",
      "Text document 38 Text fragment 1 - generated: 22 questions\n",
      "Document 38 - split into 3\n",
      "Text document 38 Text fragment 2 - generated: 26 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 0 - generated: 18 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 1 - generated: 22 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 2 - generated: 21 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 3 - generated: 22 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 4 - generated: 20 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 5 - generated: 22 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 6 - generated: 20 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 7 - generated: 21 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 8 - generated: 21 questions\n",
      "Document 39 - split into 10\n",
      "Text document 39 Text fragment 9 - generated: 20 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 0 - generated: 21 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 1 - generated: 21 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 2 - generated: 23 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 3 - generated: 21 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 4 - generated: 22 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 5 - generated: 20 questions\n",
      "Document 40 - split into 7\n",
      "Text document 40 Text fragment 6 - generated: 18 questions\n",
      "Document 41 - split into 1\n",
      "Text document 41 Text fragment 0 - generated: 29 questions\n",
      "Document 42 - split into 1\n",
      "Text document 42 Text fragment 0 - generated: 21 questions\n",
      "Document 43 - split into 1\n",
      "Text document 43 Text fragment 0 - generated: 21 questions\n",
      "Document 44 - split into 1\n",
      "Text document 44 Text fragment 0 - generated: 21 questions\n",
      "Document 45 - split into 1\n",
      "Text document 45 Text fragment 0 - generated: 20 questions\n",
      "Document 46 - split into 1\n",
      "Text document 46 Text fragment 0 - generated: 28 questions\n",
      "Document 47 - split into 5\n",
      "Text document 47 Text fragment 0 - generated: 21 questions\n",
      "Document 47 - split into 5\n",
      "Text document 47 Text fragment 1 - generated: 21 questions\n",
      "Document 47 - split into 5\n",
      "Text document 47 Text fragment 2 - generated: 21 questions\n",
      "Document 47 - split into 5\n",
      "Text document 47 Text fragment 3 - generated: 23 questions\n",
      "Document 47 - split into 5\n",
      "Text document 47 Text fragment 4 - generated: 21 questions\n",
      "Document 48 - split into 1\n",
      "Text document 48 Text fragment 0 - generated: 21 questions\n",
      "Document 49 - split into 3\n",
      "Text document 49 Text fragment 0 - generated: 21 questions\n",
      "Document 49 - split into 3\n",
      "Text document 49 Text fragment 1 - generated: 20 questions\n",
      "Document 49 - split into 3\n",
      "Text document 49 Text fragment 2 - generated: 21 questions\n",
      "Document 50 - split into 4\n",
      "Text document 50 Text fragment 0 - generated: 20 questions\n",
      "Document 50 - split into 4\n",
      "Text document 50 Text fragment 1 - generated: 20 questions\n",
      "Document 50 - split into 4\n",
      "Text document 50 Text fragment 2 - generated: 21 questions\n",
      "Document 50 - split into 4\n",
      "Text document 50 Text fragment 3 - generated: 23 questions\n",
      "Document 51 - split into 2\n",
      "Text document 51 Text fragment 0 - generated: 21 questions\n",
      "Document 51 - split into 2\n",
      "Text document 51 Text fragment 1 - generated: 21 questions\n",
      "Document 52 - split into 2\n",
      "Text document 52 Text fragment 0 - generated: 21 questions\n",
      "Document 52 - split into 2\n",
      "Text document 52 Text fragment 1 - generated: 22 questions\n",
      "Document 53 - split into 1\n",
      "Text document 53 Text fragment 0 - generated: 21 questions\n",
      "Document 54 - split into 1\n",
      "Text document 54 Text fragment 0 - generated: 20 questions\n",
      "Document 55 - split into 1\n",
      "Text document 55 Text fragment 0 - generated: 21 questions\n",
      "Document 56 - split into 1\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jban7wg4eh08sntrz9qg1dj9` on : Limit 200000, Used 199622, Requested 758. Please try again in 2m43.942999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Switching Keys\n",
      "Text document 56 Text fragment 0 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 0 - generated: 35 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 1 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 2 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 3 - generated: 23 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 4 - generated: 35 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 5 - generated: 22 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 6 - generated: 40 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 7 - generated: 22 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 8 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 9 - generated: 22 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 10 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 11 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 12 - generated: 21 questions\n",
      "Document 57 - split into 14\n",
      "Text document 57 Text fragment 13 - generated: 20 questions\n",
      "Document 58 - split into 1\n",
      "Text document 58 Text fragment 0 - generated: 20 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 0 - generated: 21 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 1 - generated: 21 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 2 - generated: 20 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 3 - generated: 21 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 4 - generated: 20 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 5 - generated: 20 questions\n",
      "Document 59 - split into 7\n",
      "Text document 59 Text fragment 6 - generated: 22 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 0 - generated: 22 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 1 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 2 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 3 - generated: 22 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 4 - generated: 20 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 5 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 6 - generated: 23 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 7 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 8 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 9 - generated: 42 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 10 - generated: 22 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 11 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 12 - generated: 34 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 13 - generated: 20 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 14 - generated: 24 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 15 - generated: 20 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 16 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 17 - generated: 20 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 18 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 19 - generated: 20 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 20 - generated: 22 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 21 - generated: 19 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 22 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 23 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 24 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 25 - generated: 29 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 26 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 27 - generated: 21 questions\n",
      "Document 60 - split into 29\n",
      "Text document 60 Text fragment 28 - generated: 20 questions\n",
      "Document 61 - split into 2\n",
      "Text document 61 Text fragment 0 - generated: 43 questions\n",
      "Document 61 - split into 2\n",
      "Text document 61 Text fragment 1 - generated: 21 questions\n",
      "Document 62 - split into 1\n",
      "Text document 62 Text fragment 0 - generated: 21 questions\n",
      "Document 63 - split into 1\n",
      "Text document 63 Text fragment 0 - generated: 21 questions\n",
      "Document 64 - split into 3\n",
      "Text document 64 Text fragment 0 - generated: 21 questions\n",
      "Document 64 - split into 3\n",
      "Text document 64 Text fragment 1 - generated: 18 questions\n",
      "Document 64 - split into 3\n",
      "Text document 64 Text fragment 2 - generated: 20 questions\n",
      "Document 65 - split into 1\n",
      "Text document 65 Text fragment 0 - generated: 21 questions\n",
      "Document 66 - split into 1\n",
      "Text document 66 Text fragment 0 - generated: 21 questions\n",
      "Document 67 - split into 1\n",
      "Text document 67 Text fragment 0 - generated: 21 questions\n",
      "Document 68 - split into 6\n",
      "Text document 68 Text fragment 0 - generated: 28 questions\n",
      "Document 68 - split into 6\n",
      "Text document 68 Text fragment 1 - generated: 19 questions\n",
      "Document 68 - split into 6\n",
      "Text document 68 Text fragment 2 - generated: 22 questions\n",
      "Document 68 - split into 6\n",
      "Text document 68 Text fragment 3 - generated: 23 questions\n",
      "Document 68 - split into 6\n",
      "Text document 68 Text fragment 4 - generated: 21 questions\n",
      "Document 68 - split into 6\n",
      "Text document 68 Text fragment 5 - generated: 26 questions\n",
      "Document 69 - split into 1\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j8wnf7tgejwaqpmd9fz4bxw3` on : Limit 200000, Used 199034, Requested 1209. Please try again in 1m44.561s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Switching Keys\n",
      "Text document 69 Text fragment 0 - generated: 33 questions\n",
      "Document 70 - split into 2\n",
      "Text document 70 Text fragment 0 - generated: 20 questions\n",
      "Document 70 - split into 2\n",
      "Text document 70 Text fragment 1 - generated: 24 questions\n",
      "Document 71 - split into 1\n",
      "Text document 71 Text fragment 0 - generated: 20 questions\n",
      "Document 72 - split into 1\n",
      "Text document 72 Text fragment 0 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 0 - generated: 23 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 1 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 2 - generated: 43 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 3 - generated: 23 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 4 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 5 - generated: 19 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 6 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 7 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 8 - generated: 31 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 9 - generated: 22 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 10 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 11 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 12 - generated: 21 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 13 - generated: 20 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 14 - generated: 23 questions\n",
      "Switching Keys\n",
      "Text document 73 Text fragment 14 - generated: 22 questions\n",
      "Document 73 - split into 16\n",
      "Text document 73 Text fragment 15 - generated: 22 questions\n",
      "Document 74 - split into 1\n",
      "Text document 74 Text fragment 0 - generated: 23 questions\n",
      "Document 75 - split into 2\n",
      "Text document 75 Text fragment 0 - generated: 24 questions\n",
      "Document 75 - split into 2\n",
      "Text document 75 Text fragment 1 - generated: 21 questions\n",
      "Document 76 - split into 1\n",
      "Text document 76 Text fragment 0 - generated: 20 questions\n",
      "Document 77 - split into 1\n",
      "Text document 77 Text fragment 0 - generated: 21 questions\n",
      "Document 78 - split into 3\n",
      "Text document 78 Text fragment 0 - generated: 24 questions\n",
      "Document 78 - split into 3\n",
      "Text document 78 Text fragment 1 - generated: 21 questions\n",
      "Document 78 - split into 3\n",
      "Text document 78 Text fragment 2 - generated: 31 questions\n",
      "Document 79 - split into 3\n",
      "Text document 79 Text fragment 0 - generated: 22 questions\n",
      "Document 79 - split into 3\n",
      "Text document 79 Text fragment 1 - generated: 21 questions\n",
      "Document 79 - split into 3\n",
      "Text document 79 Text fragment 2 - generated: 21 questions\n",
      "Document 80 - split into 2\n",
      "Text document 80 Text fragment 0 - generated: 21 questions\n",
      "Document 80 - split into 2\n",
      "Text document 80 Text fragment 1 - generated: 21 questions\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:52:14.198231Z",
     "start_time": "2024-10-28T10:52:14.198183Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "68d3f630900c59c5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
